{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa63a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682b3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "## Langsmith Tracking\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd7242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x78f013fa1240> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x78f026164ca0> root_client=<openai.OpenAI object at 0x78f013b05c90> root_async_client=<openai.AsyncOpenAI object at 0x78f0240b6ef0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result = llm.invoke('What is generative AI?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "966cf8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a class of algorithms that are designed to create new content. These algorithms learn from a set of data and use that learning to produce new, original outputs that are statistically similar to the input data. Generative AI can be used for a variety of applications, such as generating text, images, music, and even code. Some of the most notable techniques in generative AI include:\n",
      "\n",
      "1. **Generative Adversarial Networks (GANs):** GANs consist of two neural networks—the generator and the discriminator—that are trained simultaneously. The generator tries to create data that is indistinguishable from the real data, while the discriminator attempts to distinguish between real and generated data.\n",
      "\n",
      "2. **Variational Autoencoders (VAEs):** VAEs are a type of autoencoder that learns to encode input data into a latent space and then decode the latent representation back into data. They are used to generate new data samples that are similar to the input data.\n",
      "\n",
      "3. **Transformers:** These are particularly used in natural language processing. Models like GPT (Generative Pre-trained Transformer) are based on transformer architecture and are capable of generating human-like text by predicting what comes next in a sentence or series of sentences.\n",
      "\n",
      "4. **Diffusion Models:** These are newer approaches to generating images, where the model learns to reverse a process of gradually adding noise to training data samples, eventually being able to start from noise and generate new images.\n",
      "\n",
      "Generative AI is widely used in applications such as content creation, image synthesis, data augmentation, drug discovery, and more, offering significant breakthroughs in automating creative processes and generating realistic data.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e43313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Your are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'Your are an expert AI Engineer. Provide me answers based on the questions'),\n",
    "        ('user', '{input}')\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e724d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool developed by LangChain to enhance the development and deployment of applications using large language models (LLMs). It is designed to assist in the creation of \"guardrails\" for these applications, helping developers fine-tune their functionality and improve their reliability. Some of the main features of Langsmith include:\n",
      "\n",
      "1. **Evaluation**: Langsmith provides functionalities to evaluate and test LLM applications to ensure that they perform as expected.\n",
      "\n",
      "2. **Tracing**: The tool allows developers to trace requests and responses, helping them to understand how their applications are interacting with LLMs and diagnose any issues.\n",
      "\n",
      "3. **Monitoring**: Post-deployment, Langsmith offers monitoring capabilities to keep an eye on applications' performance and reliability in a production environment.\n",
      "\n",
      "Overall, Langsmith aims to bridge the gap between the initial development of LLM-based applications and their successful deployment and maintenance, making them more robust and effective.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({'input': 'Can you tel me about Langsmith?'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13723a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba8c7120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a toolkit designed to enhance the development and deployment of LLM-powered applications. It focuses on improving observability, testing, and fine-tuning of these applications. Langsmith lets developers track and analyze the performance of language models, manage and execute tests, and refine applications based on user interactions and test results. As part of the Langchain ecosystem, it provides critical features to help developers optimize the functionality and reliability of their AI applications.\n"
     ]
    }
   ],
   "source": [
    "### StrOutputParser\n",
    "from langchain.schema  import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
